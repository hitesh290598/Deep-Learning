{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # string searching and manipulating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Datasets/Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'candidate', 'candidate_confidence', 'relevant_yn',\n",
       "       'relevant_yn_confidence', 'sentiment', 'sentiment_confidence',\n",
       "       'subject_matter', 'subject_matter_confidence', 'candidate_gold', 'name',\n",
       "       'relevant_yn_gold', 'retweet_count', 'sentiment_gold',\n",
       "       'subject_matter_gold', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_id', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.sentiment != \"Neutral\"] # delete the neutral sentiments\n",
    "data['text'] = data['text'].apply(lambda x: x.lower()) # all text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        rt @scottwalker: didn't catch the full #gopdeb...\n",
       "3        rt @robgeorge: that carly fiorina is trending ...\n",
       "4        rt @danscavino: #gopdebate w/ @realdonaldtrump...\n",
       "5        rt @gregabbott_tx: @tedcruz: \"on my first day ...\n",
       "6        rt @warriorwoman91: i liked her and was happy ...\n",
       "                               ...                        \n",
       "13866    rt @cappy_yarbrough: love to see men who will ...\n",
       "13867    rt @georgehenryw: who thought huckabee exceede...\n",
       "13868    rt @lrihendry: #tedcruz as president, i will a...\n",
       "13869    rt @jrehling: #gopdebate donald trump says tha...\n",
       "13870    rt @lrihendry: #tedcruz headed into the presid...\n",
       "Name: text, Length: 10729, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4472\n",
      "16986\n"
     ]
    }
   ],
   "source": [
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ')\n",
    "    \n",
    "tokenizer = Tokenizer(num_words=2000, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(2000, embed_dim, input_length = X.shape[1])) #used to create word vectors for incoming words\n",
    "\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "\n",
    "model.add(LSTM(196, dropout= 0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax')) # output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        Positive\n",
       "3        Positive\n",
       "4        Positive\n",
       "5        Positive\n",
       "6        Negative\n",
       "           ...   \n",
       "13866    Negative\n",
       "13867    Positive\n",
       "13868    Positive\n",
       "13869    Negative\n",
       "13870    Positive\n",
       "Name: sentiment, Length: 10729, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7188, 29) (7188, 2)\n",
      "(3541, 29) (3541, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 7s - loss: 0.4317 - acc: 0.8168\n",
      "Epoch 2/7\n",
      " - 5s - loss: 0.3210 - acc: 0.8646\n",
      "Epoch 3/7\n",
      " - 5s - loss: 0.2806 - acc: 0.8819\n",
      "Epoch 4/7\n",
      " - 5s - loss: 0.2525 - acc: 0.8939\n",
      "Epoch 5/7\n",
      " - 5s - loss: 0.2257 - acc: 0.9068\n",
      "Epoch 6/7\n",
      " - 5s - loss: 0.2035 - acc: 0.9167\n",
      "Epoch 7/7\n",
      " - 5s - loss: 0.1827 - acc: 0.9226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8a2dab9b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs=7, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.48\n",
      "acc: 0.85\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose=2, batch_size= batch_size)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 62.7831715210356 %\n",
      "neg_acc 92.19143576826197 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0,0,0,0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]), batch_size=1, verbose=2)[0]\n",
    "    \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "            \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1 #actual negative cnt\n",
    "    else:\n",
    "        pos_cnt += 1 #actual pos cnt\n",
    "        \n",
    "        \n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.6(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
